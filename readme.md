# SACCä½¿ç”¨æŒ‡å—

SACCæ˜¯AIåŒ–å­¦ç»„æ¨å‡ºçš„å…¨ç½‘æœ€å¥½ç”¨çš„ğŸ›â¤ğŸ¤—â¤ğŸš€ Slurm+Huggingface+Deepspeedå¤§æ¨¡å‹è®­ç»ƒå·¥å…·ï¼Œå› ä¸ºæˆ‘ä»¬å®åœ¨æ‰¾ä¸åˆ°ç±»ä¼¼å·¥å…·ï¼Œæ‰€ä»¥ä¹Ÿæ˜¯å…¨ç½‘æœ€å¥½ç”¨çš„ğŸ˜€

## å®‰è£…

```Bash
git clone https://github.com/trotsky1997/sacc_beijingcloud.git
cd sacc
bash ./install.sh
```

## ä½¿ç”¨

```Bash
 sacc  --num_nodes 2 --gpu_per_nodes 4 --cpu_per_nodes 16 --mem_per_cpu 8  [ç›®æ ‡è®­ç»ƒè„šæœ¬åŠå…¶å‚æ•°]
```

### ç¤ºä¾‹

```Bash
cd LLaMA-Factory/
sacc  --num_nodes 2 --gpu_per_nodes 4 --cpu_per_nodes 16 --mem_per_cpu 8   src/train_bash.py  --stage pt     --model_name_or_path microsoft/phi-1_5    --do_train     --dataset chemllm     --finetuning_type full    --output_dir phi-1_5_checkpoint_2     --overwrite_cache     --lr_scheduler_type cosine     --logging_steps 10     --save_steps 1000     --learning_rate 5e-5     --num_train_epochs 3.0     --plot_loss     --bf16 --overwrite_output_dir --streaming --max_steps 9999999999
```

## å‚æ•°

- --num_nodesï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ‚¨çš„ä½œä¸šçš„èŠ‚ç‚¹æ•°ã€‚ä¸€ä¸ªèŠ‚ç‚¹æ˜¯ä¸€ä¸ªè¿è¡Œæ‚¨çš„ä»£ç çš„å•ä¸ªè®¡ç®—æœºæˆ–æœåŠ¡å™¨ã€‚é»˜è®¤å€¼æ˜¯ 2ï¼Œè¿™æ„å‘³ç€æ‚¨çš„ä½œä¸šå°†åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„æ•´æ•°æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --num_nodes 4ã€‚
- --gpu_per_nodesï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ¯ä¸ªèŠ‚ç‚¹çš„ GPU æ•°é‡ã€‚GPU æ˜¯å›¾å½¢å¤„ç†å•å…ƒï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œå¹¶è¡Œè®¡ç®—æ¥åŠ é€Ÿæ‚¨çš„ä»£ç ã€‚é»˜è®¤å€¼æ˜¯ 8ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªèŠ‚ç‚¹å°†æœ‰ 8 ä¸ª GPU å¯ç”¨ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„æ•´æ•°æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --gpu_per_nodes 2ã€‚
- --cpu_per_nodesï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ¯ä¸ªèŠ‚ç‚¹çš„ CPU æ•°é‡ã€‚CPU æ˜¯ä¸­å¤®å¤„ç†å•å…ƒï¼Œé¡ºåºæ‰§è¡Œæ‚¨çš„ä»£ç ã€‚é»˜è®¤å€¼æ˜¯ 8ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªèŠ‚ç‚¹å°†æœ‰ 8 ä¸ª CPU å¯ç”¨ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„æ•´æ•°æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --cpu_per_nodes 16ã€‚
- --mem_per_cpuï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ¯ä¸ª CPU çš„å†…å­˜æ•°é‡ã€‚å†…å­˜æ˜¯åœ¨æ‚¨çš„ä»£ç è¿è¡Œæ—¶å­˜å‚¨æ‚¨çš„æ•°æ®å’Œå˜é‡çš„ç©ºé—´ã€‚é»˜è®¤å€¼æ˜¯ 8ï¼Œè¿™æ„å‘³ç€æ¯ä¸ª CPU å°†æœ‰ 8 GB çš„å†…å­˜å¯ç”¨ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„æ•´æ•°æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --mem_per_cpu 4ã€‚
- --job_nameï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ‚¨çš„ä½œä¸šçš„åç§°ã€‚ä½œä¸šåç§°æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”¨äºæ ‡è¯†æ‚¨çš„ä½œä¸šå¹¶å¸®åŠ©æ‚¨è·Ÿè¸ªå®ƒã€‚é»˜è®¤å€¼æ˜¯æ‚¨çš„ç”¨æˆ·ååé¢åŠ ä¸Š "_no_name"ï¼Œè¿™æ„å‘³ç€æ‚¨çš„ä½œä¸šåç§°å°†æ˜¯ç±»ä¼¼äº "alice_no_name" çš„ä¸œè¥¿ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„å­—ç¬¦ä¸²æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --job_name "my_awesome_job"ã€‚
- --partitionï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†æ‚¨çš„ä½œä¸šå°†è¿è¡Œåœ¨å“ªä¸ªé›†ç¾¤åˆ†åŒºã€‚åˆ†åŒºæ˜¯ä¸€ç»„å…·æœ‰ç›¸ä¼¼ç‰¹å¾å’Œå¯ç”¨æ€§çš„èŠ‚ç‚¹ã€‚é»˜è®¤å€¼æ˜¯ "AI4Phys"ï¼Œè¿™æ„å‘³ç€æ‚¨çš„ä½œä¸šå°†è¿è¡Œåœ¨ AI4Phys åˆ†åŒºï¼Œè¿™æ˜¯ä¸“é—¨ç”¨äºäººå·¥æ™ºèƒ½å’Œç‰©ç†ç ”ç©¶çš„åˆ†åŒºã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªä¸åŒçš„å­—ç¬¦ä¸²æ¥æ”¹å˜è¿™ä¸ªå€¼ï¼Œä¾‹å¦‚ --partition "general"ã€‚

## Parameters

- --num_nodes: This option specifies the number of nodes for your job. A node is a single computer or server that runs your code. The default value is 2, which means your job will run on two nodes. You can change this value by passing a different integer to the option, such as --num_nodes 4.
- --gpu_per_nodes: This option specifies the number of GPUs per node for your job. A GPU is a graphics processing unit that can accelerate your code by performing parallel computations. The default value is 8, which means each node will have 8 GPUs available. You can change this value by passing a different integer to the option, such as --gpu_per_nodes 2.
- --cpu_per_nodes: This option specifies the number of CPUs per node for your job. A CPU is a central processing unit that executes your code sequentially. The default value is 8, which means each node will have 8 CPUs available. You can change this value by passing a different integer to the option, such as --cpu_per_nodes 16.
- --mem_per_cpu: This option specifies the number of GBs of memory per CPU for your job. Memory is the storage space that holds your data and variables while your code is running. The default value is 8, which means each CPU will have 8 GBs of memory available. You can change this value by passing a different integer to the option, such as --mem_per_cpu 4.
- --job_name: This option specifies the name of your job. A job name is a string that identifies your job and helps you keep track of it. The default value is your username followed by "_no_name", which means your job name will be something like "alice_no_name". You can change this value by passing a different string to the option, such as --job_name "my_awesome_job".
- --partition: This option specifies the partition of the cluster that your job will run on. A partition is a group of nodes that have similar characteristics and availability. The default value is "AI4Phys", which means your job will run on the AI4Phys partition, which is dedicated to artificial intelligence and physics research. You can change this value by passing a different string to the option, such as --partition "general".
